{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devcoding17/ADF/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark\n",
        "# !pip install pyspark\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"PySparkTutorial\").getOrCreate()\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)]\n",
        "columns = [\"Name\", \"ID\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "df.show()\n",
        "\n",
        "# Perform a transformation (e.g., filter)\n",
        "filtered_df = df.filter(df.ID > 1)\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "print(\"Filtered DataFrame (ID > 1):\")\n",
        "filtered_df.show()\n",
        "\n",
        "# Stop the SparkSession (optional, but good practice)\n",
        "# spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WwIfy-qW5Wg",
        "outputId": "abd19ee3-c1b8-4c62-8f38-7069be753f35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+-------+---+\n",
            "|   Name| ID|\n",
            "+-------+---+\n",
            "|  Alice|  1|\n",
            "|    Bob|  2|\n",
            "|Charlie|  3|\n",
            "+-------+---+\n",
            "\n",
            "Filtered DataFrame (ID > 1):\n",
            "+-------+---+\n",
            "|   Name| ID|\n",
            "+-------+---+\n",
            "|    Bob|  2|\n",
            "|Charlie|  3|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.sparkContext.uiWebUrl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPiTbPwUpA8S",
        "outputId": "fb40d0fe-b0fa-4b18-ce26-dbfc8bbf07d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://59bd17eb46fa:4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mega_csv = spark.read.csv('MegaMart.csv', header=True, inferSchema=True)\n",
        "\n",
        "mega_csv.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV-p5tPsqkQb",
        "outputId": "aae1d13b-a3ee-417a-fa19-1627cde7ed37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----------+----------+----------------+--------------------+--------+--------------+--------------+------------+\n",
            "|order_id|user_id|order_date|product_id|product_category|        product_name|quantity|price_per_unit|payment_method|order_status|\n",
            "+--------+-------+----------+----------+----------------+--------------------+--------+--------------+--------------+------------+\n",
            "|    1001|   U188|2025-04-20|      P940|         Fashion|            Sneakers|       2|         58.53|        PayPal|   Cancelled|\n",
            "|    1002|   U062|2025-04-16|      P794|         Fashion|             T-Shirt|       3|         83.76|           UPI|    Returned|\n",
            "|    1003|   U058|2025-04-18|      P326|         Fashion|          Sunglasses|       2|         78.85|        PayPal|  Processing|\n",
            "|    1004|   U011|2025-04-10|      P574|         Fashion|          Sunglasses|       5|         46.49|        PayPal|   Delivered|\n",
            "|    1005|   U003|2025-04-19|      P988|      Home Decor|         Photo Frame|       2|         78.61|        PayPal|    Returned|\n",
            "|    1006|   U017|2025-04-15|      P328|         Kitchen|           Knife Set|       4|         53.51|   Credit Card|    Returned|\n",
            "|    1007|   U129|2025-04-23|      P786|      Home Decor|          Wall Clock|       5|         12.71|   Credit Card|    Returned|\n",
            "|    1008|   U102|2025-04-15|      P101|      Home Decor|         Photo Frame|       1|          46.6|    Debit Card|   Cancelled|\n",
            "|    1009|   U040|2025-04-04|      P610|         Kitchen|             Toaster|       4|         35.87|   Credit Card|  Processing|\n",
            "|    1010|   U186|2025-04-29|      P354|         Kitchen|           Microwave|       1|         30.95|   Credit Card|  Processing|\n",
            "|    1011|   U168|2025-05-02|      P706|     Electronics|         USB-C Cable|       4|         18.79|        PayPal|  Processing|\n",
            "|    1012|   U148|2025-04-24|      P315|         Fashion|          Sunglasses|       5|         69.14|   Credit Card|  Processing|\n",
            "|    1013|   U140|2025-05-03|      P516|         Fashion|            Sneakers|       5|         90.64|   Credit Card|   Cancelled|\n",
            "|    1014|   U112|2025-04-18|      P111|           Books|Data Engineering 101|       1|         93.91|   Credit Card|   Cancelled|\n",
            "|    1015|   U184|2025-04-11|      P930|         Fashion|          Sunglasses|       1|          61.0|           UPI|   Cancelled|\n",
            "|    1016|   U025|2025-04-24|      P713|     Electronics|          Smartwatch|       2|         54.77|           UPI|    Returned|\n",
            "|    1017|   U021|2025-04-26|      P728|           Books|  Big Data Explained|       5|         13.42|        PayPal|   Delivered|\n",
            "|    1018|   U067|2025-04-15|      P650|     Electronics|      Wireless Mouse|       2|         18.72|    Debit Card|  Processing|\n",
            "|    1019|   U115|2025-05-03|      P973|         Kitchen|             Blender|       3|         35.68|    Debit Card|   Delivered|\n",
            "|    1020|   U159|2025-04-16|      P859|         Kitchen|             Blender|       4|         56.08|           UPI|  Processing|\n",
            "+--------+-------+----------+----------+----------------+--------------------+--------+--------------+--------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mega_csv.printSchema()\n",
        "mega_csv.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSEuMCaGXmZZ",
        "outputId": "bda211da-b362-404f-e75e-1a09568beab7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: integer (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_category: string (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- price_per_unit: double (nullable = true)\n",
            " |-- payment_method: string (nullable = true)\n",
            " |-- order_status: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mega_csv.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFoy8mi3rzo6",
        "outputId": "7834debf-2e6a-4e51-e120-342bb5d06484"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------+----------+----------------+--------------+----------------+------------------+--------------+------------+\n",
            "|summary|         order_id|user_id|product_id|product_category|  product_name|        quantity|    price_per_unit|payment_method|order_status|\n",
            "+-------+-----------------+-------+----------+----------------+--------------+----------------+------------------+--------------+------------+\n",
            "|  count|             1000|   1000|      1000|            1000|          1000|            1000|              1000|          1000|        1000|\n",
            "|   mean|           1500.5|   NULL|      NULL|            NULL|          NULL|           3.001|55.205360000000034|          NULL|        NULL|\n",
            "| stddev|288.8194360957494|   NULL|      NULL|            NULL|          NULL|1.42864972615405|25.355789976960995|          NULL|        NULL|\n",
            "|    min|             1001|   U001|      P101|           Books| AI Revolution|               1|             10.03|   Credit Card|   Cancelled|\n",
            "|    max|             2000|   U200|      P999|         Kitchen|Wireless Mouse|               5|             99.93|           UPI|    Returned|\n",
            "+-------+-----------------+-------+----------+----------------+--------------+----------------+------------------+--------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mega_csv1 = mega_csv.select('order_id')\n",
        "mega_csv1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM80y7h8sTUT",
        "outputId": "7b1625bc-925f-4c76-927f-f1ae6d4fad53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|order_id|\n",
            "+--------+\n",
            "|    1001|\n",
            "|    1002|\n",
            "|    1003|\n",
            "|    1004|\n",
            "|    1005|\n",
            "|    1006|\n",
            "|    1007|\n",
            "|    1008|\n",
            "|    1009|\n",
            "|    1010|\n",
            "|    1011|\n",
            "|    1012|\n",
            "|    1013|\n",
            "|    1014|\n",
            "|    1015|\n",
            "|    1016|\n",
            "|    1017|\n",
            "|    1018|\n",
            "|    1019|\n",
            "|    1020|\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mega_csv2 = mega_csv.select(['order_id', 'product_id']) \\\n",
        "            .orderBy('order_id', ascending=False)\n",
        "\n",
        "mega_csv2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvMrhlMvvW2p",
        "outputId": "7ce42fc2-959d-4eb5-daad-6ee0122a77d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|order_id|product_id|\n",
            "+--------+----------+\n",
            "|    2000|      P870|\n",
            "|    1999|      P900|\n",
            "|    1998|      P651|\n",
            "|    1997|      P126|\n",
            "|    1996|      P860|\n",
            "|    1995|      P126|\n",
            "|    1994|      P673|\n",
            "|    1993|      P171|\n",
            "|    1992|      P969|\n",
            "|    1991|      P101|\n",
            "|    1990|      P123|\n",
            "|    1989|      P125|\n",
            "|    1988|      P649|\n",
            "|    1987|      P848|\n",
            "|    1986|      P289|\n",
            "|    1985|      P167|\n",
            "|    1984|      P820|\n",
            "|    1983|      P551|\n",
            "|    1982|      P314|\n",
            "|    1981|      P237|\n",
            "+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the DataFrame as a temporary view\n",
        "mega_csv.createOrReplaceTempView(\"mega_csv_view\")\n",
        "\n",
        "# Now you can query the temporary view using spark.sql\n",
        "df1 = spark.sql(\"SELECT distinct(order_status) FROM mega_csv_view\")\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPP_FJt0xn-7",
        "outputId": "7dad4e10-0e45-4d9b-d566-c0f7128952e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|order_status|\n",
            "+------------+\n",
            "|    Returned|\n",
            "|  Processing|\n",
            "|   Cancelled|\n",
            "|   Delivered|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.sql(\"\"\"SELECT product_id\n",
        "                 FROM mega_csv_view\n",
        "                 WHERE order_status = 'Returned'  \"\"\")\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TiVNjvO3B8R",
        "outputId": "40c170b5-39e9-4f79-fc75-4f36c6e1acb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|product_id|\n",
            "+----------+\n",
            "|      P794|\n",
            "|      P988|\n",
            "|      P328|\n",
            "|      P786|\n",
            "|      P713|\n",
            "|      P960|\n",
            "|      P311|\n",
            "|      P106|\n",
            "|      P948|\n",
            "|      P840|\n",
            "|      P324|\n",
            "|      P834|\n",
            "|      P171|\n",
            "|      P371|\n",
            "|      P553|\n",
            "|      P750|\n",
            "|      P862|\n",
            "|      P807|\n",
            "|      P390|\n",
            "|      P235|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "205ece80"
      },
      "source": [
        "### More PySpark Examples\n",
        "\n",
        "This section will cover more PySpark operations, from basic data manipulation to more advanced concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4e31bce"
      },
      "source": [
        "Let's start with some basic data manipulation operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78b4d500"
      },
      "source": [
        "# Select specific columns\n",
        "selected_cols_df = df.select(\"Name\")\n",
        "print(\"DataFrame with selected columns:\")\n",
        "selected_cols_df.show()\n",
        "\n",
        "# Add a new column\n",
        "df_with_new_col = df.withColumn(\"Status\", when(df.ID > 2, \"Senior\").otherwise(\"Junior\"))\n",
        "print(\"DataFrame with new column:\")\n",
        "df_with_new_col.show()\n",
        "\n",
        "# Drop a column\n",
        "df_without_id = df_with_new_col.drop(\"ID\")\n",
        "print(\"DataFrame after dropping a column:\")\n",
        "df_without_id.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8621b4e"
      },
      "source": [
        "Now let's look at handling missing values and performing aggregations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "021efd2c"
      },
      "source": [
        "from pyspark.sql.functions import avg, col\n",
        "\n",
        "# Create a DataFrame with missing values\n",
        "data_missing = [(\"Alice\", 1, 100), (\"Bob\", 2, None), (\"Charlie\", 3, 150), (\"David\", 4, None)]\n",
        "columns_missing = [\"Name\", \"ID\", \"Score\"]\n",
        "df_missing = spark.createDataFrame(data_missing, columns_missing)\n",
        "print(\"DataFrame with missing values:\")\n",
        "df_missing.show()\n",
        "\n",
        "# Drop rows with missing values\n",
        "df_no_missing = df_missing.na.drop()\n",
        "print(\"DataFrame after dropping rows with missing values:\")\n",
        "df_no_missing.show()\n",
        "\n",
        "# Fill missing values\n",
        "df_filled_missing = df_missing.na.fill(0)\n",
        "print(\"DataFrame after filling missing values:\")\n",
        "df_filled_missing.show()\n",
        "\n",
        "# Aggregate data\n",
        "avg_score = df_missing.agg(avg(col(\"Score\")).alias(\"AverageScore\"))\n",
        "print(\"Average score:\")\n",
        "avg_score.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10c121d"
      },
      "source": [
        "Finally, let's demonstrate joining DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be7c5f19"
      },
      "source": [
        "# Create another DataFrame\n",
        "data_address = [(\"Alice\", \"New York\"), (\"Bob\", \"Los Angeles\"), (\"Charlie\", \"Chicago\")]\n",
        "columns_address = [\"Name\", \"City\"]\n",
        "df_address = spark.createDataFrame(data_address, columns_address)\n",
        "print(\"Address DataFrame:\")\n",
        "df_address.show()\n",
        "\n",
        "# Join DataFrames\n",
        "joined_df = df.join(df_address, on=\"Name\", how=\"inner\")\n",
        "print(\"Joined DataFrame:\")\n",
        "joined_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df.select(lit(5), lit(\"five\"), lit(5.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvPtrPaBf_Hp",
        "outputId": "2cdfb909-0c2d-43e7-a503-6917916a1252"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[5: int, five: string, 5.0: double]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "df.select(\n",
        "ltrim(lit(\"  HELLO  \")).alias(\"ltrim\"),\n",
        "rtrim(lit(\"  HELLO  \")).alias(\"rtrim\"),\n",
        "trim(lit(\"  HELLO  \")).alias(\"trim\"),\n",
        "lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
        "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80gSKPrHchZo",
        "outputId": "aee7f579-a5af-4305-8961-28b6277f68ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+---+----------+\n",
            "|  ltrim|  rtrim| trim| lp|        rp|\n",
            "+-------+-------+-----+---+----------+\n",
            "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
            "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
            "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
            "+-------+-------+-----+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dateDF = spark.range(10)\\\n",
        "\t.withColumn(\"today\", current_date())\\\n",
        "\t.withColumn(\"now\", current_timestamp())\n",
        "\n",
        "dateDF.createOrReplaceTempView(\"dateTable\")\n",
        "\n",
        "dateDF.printSchema()\n",
        "dateDF.show(3,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoHWaeFudCln",
        "outputId": "9e39389a-5a20-498f-a58c-cb52385cbdf3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = false)\n",
            " |-- today: date (nullable = false)\n",
            " |-- now: timestamp (nullable = false)\n",
            "\n",
            "+---+----------+--------------------------+\n",
            "|id |today     |now                       |\n",
            "+---+----------+--------------------------+\n",
            "|0  |2025-08-30|2025-08-30 10:12:35.682768|\n",
            "|1  |2025-08-30|2025-08-30 10:12:35.682768|\n",
            "|2  |2025-08-30|2025-08-30 10:12:35.682768|\n",
            "+---+----------+--------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}